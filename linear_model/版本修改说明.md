## 2018.4.27
相比最初的版本增加了牛顿法的迭代，同时现在已经支持多分类。

例子的对比来源于[这里](http://sklearn.apachecn.org/cn/0.19.0/modules/sgd.html)

几个需要注意的点：
1. 关于溢出，可以看这篇[文章](http://fa.bianp.net/blog/2013/numerical-optimizers-for-logistic-regression/)，不同的只是文章里的损失函数用的
是核方法，而我的损失函数与西瓜书一致（形式上更像吴恩达视频里的，但本质是一样的，这种形式也更好理解一些）。
2. 数据预处理的效果超乎想象，具体原理还有待找相关文章。代码的编写中我一直忽视这一点，困扰于为什么拟合效果与初始向量的选取如此强相关，对X进行预处理
后效果就好多了。
3. 最后对比得到的结果还是有不小的差距，可能的原因是没有加L2正则，但我现在时间不够，正则会放到之后再做。
4. 还是要撸代码，只有撸代码才能知道很多细节，知道参数怎么选。